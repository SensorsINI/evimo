@INPROCEEDINGS{EVIMO,
  author={A. {Mitrokhin} and C. {Ye} and C. {Fermüller} and Y. {Aloimonos} and T. {Delbruck}},
  booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={EV-IMO: Motion Segmentation Dataset and Learning Pipeline for Event Cameras}, 
  year={2019},
  url = {http://arxiv.org/abs/1903.07520},
  volume={},
  number={},
  pages={6105-6112},
  abstract={We present the first event-based learning approach for motion segmentation in indoor scenes and the first event-based dataset - EV-IMO- which includes accurate pixel-wise motion masks, egomotion and ground truth depth. Our approach is based on an efficient implementation of the SfM learning pipeline using a low parameter neural network architecture on event data. In addition to camera egomotion and a dense depth map, the network estimates independently moving object segmentation at the pixel-level and computes per-object 3D translational velocities of moving objects. We also train a shallow network with just 40k parameters, which is able to compute depth and egomotion. Our EV-IMO dataset features 32 minutes of indoor recording with up to 3 fast moving objects in the camera field of view. The objects and the camera are tracked using a VICON® motion capture system. By 3D scanning the room and the objects, ground truth of the depth map and pixel-wise object masks are obtained. We then train and evaluate our learning pipeline on EV-IMO and demonstrate that it is well suited for scene constrained robotics applications. SUPPLEMENTARY MATERIAL The supplementary video, code, trained models, appendix and a dataset will be made available at http://prg.cs.umd.edu/EV-IMO.html.},
  keywords={cameras;image segmentation;image sensors;image sequences;learning (artificial intelligence);motion estimation;neural net architecture;object detection;statistical analysis;video signal processing;EV-IMO dataset features;3D scanning;event-based learning approach;dense depth map;camera egomotion;event data;low parameter neural network architecture;SfM learning pipeline;truth depth;first event-based dataset;pixel-wise motion masks;indoor scenes;event cameras;motion segmentation dataset;scene constrained robotics applications;pixel-wise object masks;ground truth;motion capture system;indoor recording;shallow network;moving objects;computes per-object 3D translational velocities;pixel-level;object segmentation},
  doi={10.1109/IROS40897.2019.8968520},
  ISSN={2153-0866},
  month={Nov},}
